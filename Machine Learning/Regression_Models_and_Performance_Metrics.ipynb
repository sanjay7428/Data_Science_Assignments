{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90286d79-01c3-465d-916c-ace5385f64b8",
   "metadata": {},
   "source": [
    "## Supervised Learning: Regression Models and Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eb212d-41b0-4894-8ad1-af6f0c431c72",
   "metadata": {},
   "source": [
    "## Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b857f-9d8e-4c33-8c46-d157e2be95d1",
   "metadata": {},
   "source": [
    "What is Simple Linear Regression (SLR)?\n",
    "\n",
    "Simple Linear Regression (SLR) is one of the most basic and widely used statistical techniques used to understand the relationship between two continuous variables ‚Äî one independent variable (X) and one dependent variable (Y).\n",
    "\n",
    "In SLR, we try to model the relationship between X and Y using a straight line equation of the form:\n",
    "\n",
    "$$\n",
    "Y = b_0 + b_1X + \\varepsilon\n",
    "$$\n",
    "\n",
    "Y = Dependent (output) variable\n",
    "\n",
    "\n",
    "X = Independent (input) variable\n",
    "\n",
    "\n",
    "b0 = Intercept (value of Y when X = 0)\n",
    "\n",
    "b1 = Slope (change in Y for a one-unit change in X)\n",
    "\n",
    "ùúÄ = Error term (difference between observed and predicted values)\n",
    "\n",
    "This equation represents the best-fitting straight line that minimizes the difference between the actual data points and the predicted line ‚Äî known as the line of best fit.\n",
    "\n",
    "Purpose of Simple Linear Regression\n",
    "\n",
    "The main purposes of SLR are:\n",
    "\n",
    "Prediction\n",
    "\n",
    "It helps in predicting the value of the dependent variable (Y) based on the given independent variable (X).\n",
    "\n",
    "Example: Predicting a person‚Äôs weight (Y) based on their height (X).\n",
    "\n",
    "Understanding Relationships\n",
    "\n",
    "SLR helps to identify and measure how strongly two variables are related.\n",
    "\n",
    "Example: Determining whether there is a positive or negative relationship between temperature and ice-cream sales.\n",
    "\n",
    "Trend Analysis\n",
    "\n",
    "It is used to analyze trends and patterns over time or across data points.\n",
    "\n",
    "Example: Predicting sales growth with time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ea6bbf-e744-4d5c-845c-3e08adb4aa2f",
   "metadata": {},
   "source": [
    "## Question 2: What are the key assumptions of Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea311a7c-bef4-4124-96f0-eda2d44719c0",
   "metadata": {},
   "source": [
    "Here are the main assumptions of SLR explained in detail:\n",
    "\n",
    "1. Linearity\n",
    "\n",
    "The relationship between the independent variable (X) and the dependent variable (Y) must be linear.\n",
    "\n",
    "This means that a change in X leads to a proportional change in Y.\n",
    "\n",
    "Mathematically,   $$\n",
    "Y = b_0 + b_1X + \\varepsilon\n",
    "$$\n",
    "\n",
    "\n",
    "Example: If study hours (X) increase, marks (Y) increase in a roughly straight-line pattern.\n",
    "\n",
    "Check: Use a scatter plot of X vs Y ‚Äî the points should form a roughly straight line.\n",
    "\n",
    "2. Independence of Errors (No Autocorrelation)\n",
    "\n",
    "The residuals (errors) should be independent of each other.\n",
    "\n",
    "In other words, the error term for one observation should not influence another.\n",
    "\n",
    "Example: In time series data, if one day‚Äôs error affects the next day‚Äôs, this violates independence.\n",
    "\n",
    "Check: Use the Durbin-Watson test to detect autocorrelation.\n",
    "\n",
    "3. Homoscedasticity (Constant Variance of Errors)\n",
    "\n",
    "The residuals should have constant variance across all levels of X.\n",
    "\n",
    "This means the spread of residuals should be the same throughout the line of best fit.\n",
    "\n",
    "If violated: It leads to heteroscedasticity, making predictions unreliable.\n",
    "\n",
    "Check: Plot residuals vs predicted values ‚Äî the spread should look random and even.\n",
    "\n",
    "4. Normality of Errors\n",
    "\n",
    "The residuals (differences between actual and predicted Y values) should be normally distributed.\n",
    "\n",
    "This assumption ensures valid hypothesis tests and confidence intervals.\n",
    "\n",
    "Check: Use a histogram or Q-Q plot of residuals ‚Äî they should form a bell-shaped curve.\n",
    "\n",
    "5. No Multicollinearity (only relevant in multiple regression)\n",
    "\n",
    "In Simple Linear Regression, there is only one independent variable, so multicollinearity does not apply.\n",
    "\n",
    "However, in Multiple Linear Regression, independent variables must not be highly correlated.\n",
    "\n",
    "6. No Significant Outliers\n",
    "\n",
    "The dataset should not contain extreme outliers, as they can distort the regression line.\n",
    "\n",
    "Outliers can heavily influence the slope and intercept values.\n",
    "\n",
    "Check: Use boxplots or scatter plots to detect outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f64119-d318-4063-b2e7-4803311e0260",
   "metadata": {},
   "source": [
    "## Question 3: Write the mathematical equation for a simple linear regression model and explain each term.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3415bc02-c854-4702-98b7-75d236fe559c",
   "metadata": {},
   "source": [
    "Mathematical Equation of Simple Linear Regression (SLR)\n",
    "\n",
    "The general equation for a simple linear regression model is:\n",
    "$$\n",
    "Y = b_0 + b_1X + \\varepsilon\n",
    "$$\n",
    "\n",
    "Explanation of Each Term:\n",
    "\n",
    "Y ‚Äî Dependent Variable (Response Variable)\n",
    "\n",
    "This is the outcome or target variable that we are trying to predict or explain.\n",
    "\n",
    "Example: In a study predicting exam scores based on study hours, Y = exam score.\n",
    "\n",
    "X ‚Äî Independent Variable (Predictor Variable)\n",
    "\n",
    "This is the input or explanatory variable used to predict the dependent variable.\n",
    "\n",
    "Example: X = number of hours studied.\n",
    "\n",
    "ùëè0‚Äî Intercept (Constant Term)\n",
    "\n",
    "It represents the value of Y when X = 0.\n",
    "\n",
    "In other words, it‚Äôs where the regression line crosses the Y-axis.\n",
    "\n",
    "Example: If b0=20, it means even with 0 hours of study, a student is expected to score 20 marks.\n",
    "\n",
    "ùëè1 ‚Äî Slope (Regression Coefficient)\n",
    "\n",
    "It represents the rate of change of Y with respect to X.\n",
    "\n",
    "For every 1 unit increase in X, Y changes by \n",
    "\n",
    "Example: If b1=5, then for every extra hour of study, the score increases by 5 marks.\n",
    "\n",
    "Œµ ‚Äî Error Term (Residual)\n",
    "\n",
    "This represents the difference between the actual and predicted values of Y.\n",
    "\n",
    "It accounts for the variation in Y that cannot be explained by X.\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "Œµ=Yactual‚àíYpredicted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecaacf9-157a-4df7-a507-2704633dec9d",
   "metadata": {},
   "source": [
    "## Question 4: Provide a real-world example where simple linear regression can be applied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9981b4-e0ed-4bea-b552-655c1dbf32b8",
   "metadata": {},
   "source": [
    "Real-World Example of Simple Linear Regression (Theory Answer)\n",
    "\n",
    "Simple Linear Regression can be applied in many real-world situations where we want to study and predict the relationship between two continuous variables ‚Äî one independent variable (X) and one dependent variable (Y).\n",
    "\n",
    "Example: Predicting House Prices Based on Area\n",
    "\n",
    "One of the most common applications of Simple Linear Regression is in the real estate industry, where it is used to predict the price of a house (Y) based on its area or size (X).\n",
    "\n",
    "In this case:\n",
    "\n",
    "Dependent variable (Y): House Price\n",
    "\n",
    "Independent variable (X): Area of the house (in square feet or square meters)\n",
    "\n",
    "By applying regression analysis to historical data, we can obtain a regression equation of the form:\n",
    "\n",
    "$$\n",
    "Y = b_0 + b_1X + \\varepsilon\n",
    "$$\n",
    "\n",
    "\n",
    "This equation helps estimate the expected price of a house for a given area.\n",
    "\n",
    "Purpose of Using SLR in This Case:\n",
    "\n",
    "Prediction: To estimate the price of a house based on its size.\n",
    "\n",
    "Understanding Relationship: To understand how house size affects its price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb2645-ac5c-4806-af1c-83772ff7a904",
   "metadata": {},
   "source": [
    "## Question 5: What is the method of least squares in linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b113b0a5-9350-4647-9ea8-4bb8ff97786a",
   "metadata": {},
   "source": [
    "Method of Least Squares in Linear Regression\n",
    "\n",
    "The Method of Least Squares is a fundamental mathematical technique used in linear regression to find the best-fitting line through a set of data points.\n",
    "It works by minimizing the sum of the squares of the differences (errors) between the observed values and the predicted values produced by the regression line.\n",
    "\n",
    "1. Concept:\n",
    "\n",
    "In Simple Linear Regression, the relationship between the dependent variable (Y) and the independent variable (X) is given by:\n",
    "$$\n",
    "Y = b_0 + b_1X + \\varepsilon\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "ùëå = actual (observed) value\n",
    "\n",
    "ùëè0+ùëè1ùëã = predicted value from regression line\n",
    "\n",
    "Œµ = error (difference between actual and predicted value)\n",
    "\n",
    "The goal is to find the values of ùëè0(intercept) and ùëè1(slope) that minimize the total error across all data points.\n",
    "\n",
    "2. Principle of Least Squares:\n",
    "\n",
    "The error (residual) for each observation is:\n",
    "\n",
    "$$\n",
    "e_i = Y_i - (b_0 + b_1X_i)\n",
    "$$\n",
    "\n",
    "The Method of Least Squares minimizes the sum of squared errors (SSE):\n",
    "\n",
    "$$\n",
    "S = \\sum (Y_i - b_0 - b_1X_i)^2\n",
    "$$\n",
    "\n",
    "By squaring the errors, we:\n",
    "\n",
    "Avoid negative signs cancelling positive ones.\n",
    "\n",
    "Give more weight to larger errors (to reduce their effect).\n",
    "\n",
    "The values of ùëè0 and ùëè1 are chosen such that this sum S is as small as possible.\n",
    "\n",
    "3. Formulas for the Regression Coefficients:\n",
    "\n",
    "From calculus (minimizing S with respect to ùëè0 and ùëè1), we get:\n",
    "$$\n",
    "b_1 = \\frac{n\\sum XY - (\\sum X)(\\sum Y)}{n\\sum X^2 - (\\sum X)^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_0 = \\bar{Y} - b_1\\bar{X}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "n = \\text{number of data points}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\bar{X} = \\text{mean of } X \\text{ values}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\bar{Y} = \\text{mean of } Y \\text{ values}\n",
    "$$\n",
    "\n",
    "4. Interpretation:\n",
    "\n",
    "The slope (ùëè1) represents how much Y changes for a one-unit change in X.\n",
    "\n",
    "The intercept (ùëè0) represents the value of Y when X = 0.\n",
    "\n",
    "The resulting line Y=b0+b1X is called the line of best fit because it minimizes the total squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341f71c-c2d3-43e1-9daa-68e8701cf54a",
   "metadata": {},
   "source": [
    "## Question 6: What is Logistic Regression? How does it differ from Linear Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff8376-af0d-4193-a8ef-ddedc2f375b4",
   "metadata": {},
   "source": [
    "What is Logistic Regression?\n",
    "\n",
    "Logistic Regression is a statistical method used for classification problems, where the dependent variable is categorical rather than continuous. It is mainly used to predict the probability of an event occurring, such as whether an email is spam or not, whether a customer will buy a product, or whether a student will pass or fail an exam.\n",
    "\n",
    "Although it has the term ‚Äúregression‚Äù in its name, logistic regression is actually a classification algorithm and not a regression one.\n",
    "\n",
    "Purpose of Logistic Regression\n",
    "\n",
    "The main goal of logistic regression is to estimate the probability that a given input belongs to a particular category. It converts the linear regression output into a probability value that always lies between 0 and 1, making it suitable for binary classification tasks (like yes/no, 0/1, true/false).\n",
    "\n",
    "Mathematical Model\n",
    "\n",
    "Logistic Regression is based on the logistic (sigmoid) function, which produces an S-shaped curve. The equation is:\n",
    "$$\n",
    "P(Y = 1 \\mid X) = \\frac{1}{1 + e^{-(b_0 + b_1X)}}\n",
    "$$\n",
    "\n",
    "In this equation:\n",
    "\n",
    "P(Y=1‚à£X) represents the probability that the output Y belongs to class 1 given the input X.\n",
    "\n",
    "ùëè0 is the intercept.\n",
    "\n",
    "ùëè1 is the coefficient of the independent variable X.\n",
    "\n",
    "ùëí is the base of the natural logarithm (approximately 2.718).\n",
    "\n",
    "This formula ensures that the output will always be a value between 0 and 1\n",
    "\n",
    "Decision Rule\n",
    "\n",
    "Once the probability value is obtained, we apply a decision threshold:\n",
    "\n",
    "If the probability is greater than or equal to 0.5, the model predicts class 1 (e.g., yes, success, positive).\n",
    "\n",
    "If the probability is less than 0.5, the model predicts class 0 (e.g., no, failure, negative).\n",
    "\n",
    "This threshold can be adjusted depending on the problem‚Äôs requirements.\n",
    "\n",
    "Example\n",
    "\n",
    "Suppose we use logistic regression to predict whether a student will pass or fail based on the number of study hours. The model might predict a probability of 0.8 for passing. Since 0.8 is greater than 0.5, the model classifies the student as ‚ÄúPass.‚Äù\n",
    "\n",
    "Difference Between Logistic Regression and Linear Regression\n",
    "\n",
    "Although both models look similar, they are used for different purposes.\n",
    "Linear Regression is used when the dependent variable is continuous, such as predicting house prices, sales, or temperature. It provides a numeric value as output and follows a straight-line relationship between the variables.\n",
    "\n",
    "In contrast, Logistic Regression is used when the dependent variable is categorical, such as predicting whether an email is spam or not. Instead of giving a continuous value, it provides a probability between 0 and 1 using the sigmoid function. The relationship between the input variable and the output probability is non-linear, forming an S-shaped curve rather than a straight line.\n",
    "\n",
    "In simple terms, linear regression predicts ‚Äúhow much,‚Äù while logistic regression predicts ‚Äúwhich category.‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c317605-1107-4804-957b-275b7103d2f2",
   "metadata": {},
   "source": [
    "## Question 7: Name and briefly describe three common evaluation metrics for regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb353e3-7961-4054-b608-9024888c177d",
   "metadata": {},
   "source": [
    "### **Question 7: Name and briefly describe three common evaluation metrics for regression models**\n",
    "\n",
    "When evaluating a **regression model**, we need to measure how close the predicted values are to the actual values.  \n",
    "Three of the most common evaluation metrics used are **Mean Absolute Error (MAE)**, **Mean Squared Error (MSE)**, and **Root Mean Squared Error (RMSE)**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Mean Absolute Error (MAE)**\n",
    "\n",
    "**Definition:**  \n",
    "MAE measures the **average magnitude of the errors** between the predicted and actual values.  \n",
    "It does not consider the direction of the errors (positive or negative).\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "\\[\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |Y_i - \\hat{Y_i}|\n",
    "\\]\n",
    "\n",
    "Where:  \n",
    "- \\( Y_i \\) = actual value  \n",
    "- \\( \\hat{Y_i} \\) = predicted value  \n",
    "- \\( n \\) = number of data points  \n",
    "\n",
    "**Interpretation:**  \n",
    "MAE gives the average error in the same units as the target variable.  \n",
    "A **lower MAE** indicates a better model.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Mean Squared Error (MSE)**\n",
    "\n",
    "**Definition:**  \n",
    "MSE measures the **average of the squared differences** between the actual and predicted values.  \n",
    "It penalizes larger errors more than smaller ones.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "\\[\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\hat{Y_i})^2\n",
    "\\]\n",
    "\n",
    "**Interpretation:**  \n",
    "A smaller MSE value indicates that the model‚Äôs predictions are closer to the actual data.  \n",
    "Because the errors are squared, MSE is sensitive to outliers.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Root Mean Squared Error (RMSE)**\n",
    "\n",
    "**Definition:**  \n",
    "RMSE is the **square root of the Mean Squared Error (MSE)**.  \n",
    "It represents the **standard deviation of prediction errors**.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "\\[\n",
    "RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\hat{Y_i})^2}\n",
    "\\]\n",
    "\n",
    "**Interpretation:**  \n",
    "RMSE provides an error measure in the same units as the dependent variable.  \n",
    "A **lower RMSE** means the model predictions are more accurate.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- **MAE** ‚Üí Average size of prediction errors.  \n",
    "- **MSE** ‚Üí Average of squared errors (penalizes larger errors).  \n",
    "- **RMSE** ‚Üí Square root of MSE, interpretable in original units.  \n",
    "\n",
    "A good regression model aims to **minimize MAE, MSE, and RMSE** for better accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b477852d-1b4b-4147-a3d7-7545af0ec1a3",
   "metadata": {},
   "source": [
    "## Question 8: What is the purpose of the R-squared metric in regression analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee58eef-c882-4fe8-8e4d-22cff1e8bf0b",
   "metadata": {},
   "source": [
    "### **Question 8: What is the purpose of the R-squared metric in regression analysis?**\n",
    "\n",
    "\n",
    "\n",
    "### **Definition**\n",
    "\n",
    "**R-squared (R¬≤)**, also known as the **Coefficient of Determination**, is a statistical measure used to evaluate how well a **regression model** explains the variability of the dependent variable.  \n",
    "It represents the **proportion of the variance** in the dependent variable that can be **explained by the independent variable(s)** in the model.\n",
    "\n",
    "\n",
    "### **Formula**\n",
    "\n",
    "\\[\n",
    "R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\n",
    "\\]\n",
    "\n",
    "Where:  \n",
    "- \\( SS_{res} = \\sum (Y_i - \\hat{Y_i})^2 \\) ‚Üí **Residual Sum of Squares** (unexplained variation)  \n",
    "- \\( SS_{tot} = \\sum (Y_i - \\bar{Y})^2 \\) ‚Üí **Total Sum of Squares** (total variation in data)  \n",
    "- \\( Y_i \\) = actual values  \n",
    "- \\( \\hat{Y_i} \\) = predicted values  \n",
    "- \\( \\bar{Y} \\) = mean of actual values  \n",
    "\n",
    "\n",
    "\n",
    "### **Interpretation**\n",
    "\n",
    "- **R¬≤ = 1 (or 100%)** ‚Üí Perfect fit. The regression model explains all the variability in the data.  \n",
    "- **R¬≤ = 0** ‚Üí The model explains none of the variability; it does no better than the mean.  \n",
    "- **Higher R¬≤ values** indicate that the model fits the data better.\n",
    "\n",
    "For example,  \n",
    "if \\( R^2 = 0.85 \\), it means that **85% of the variation** in the dependent variable can be explained by the model, while **15%** is due to random noise or other factors not included in the model.\n",
    "\n",
    "\n",
    "\n",
    "### **Purpose of R-squared**\n",
    "\n",
    "1. **Measure of Goodness of Fit:**  \n",
    "   It helps determine how well the regression line fits the observed data.\n",
    "\n",
    "2. **Model Evaluation:**  \n",
    "   R¬≤ is used to compare different models ‚Äî a model with a higher R¬≤ generally fits the data better.\n",
    "\n",
    "3. **Explained Variance:**  \n",
    "   It quantifies how much of the variation in the dependent variable is captured by the independent variables.\n",
    "\n",
    "\n",
    "\n",
    "### **Limitations**\n",
    "\n",
    "- A high R¬≤ does **not always mean** the model is good; it could be **overfitting** the data.  \n",
    "- R¬≤ **cannot determine causation** ‚Äî only the strength of the relationship.  \n",
    "- Adding more variables will always increase R¬≤, even if they are irrelevant (this is why **Adjusted R¬≤** is also used).\n",
    "\n",
    "\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "R-squared is a key metric in regression analysis that shows **how well the model explains the data‚Äôs variability**.  \n",
    "A higher R¬≤ indicates a better model fit, but it should always be interpreted carefully alongside other metrics like **RMSE** or **MAE** to ensure the model is both accurate and reliable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c8cd4c-2355-48ad-b0ca-3f71b432325d",
   "metadata": {},
   "source": [
    "## Question 9: Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db1abc73-6a5d-407b-97f8-b7a3e6513373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope (b1): 0.6\n",
      "Intercept (b0): 2.2\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Example dataset\n",
    "# Independent variable (X) - must be 2D for sklearn\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "\n",
    "# Dependent variable (Y)\n",
    "Y = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, Y)\n",
    "\n",
    "# Print the slope (coefficient) and intercept\n",
    "print(\"Slope (b1):\", model.coef_[0])\n",
    "print(\"Intercept (b0):\", model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368687b4-9e82-488e-ad01-923dbd0c8be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
